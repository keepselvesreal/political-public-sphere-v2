#!/usr/bin/env python3
"""
FMKorea ìŠ¤í¬ë˜í¼ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.
"""

import asyncio
import json
import sys
import os

# ìŠ¤í¬ë˜í¼ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'scraping', 'scrapers'))

from fmkorea_scraper_v3 import FMKoreaScraper, scrape_and_save

async def test_scraper():
    """ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    # í…ŒìŠ¤íŠ¸í•  URL (ì œê³µëœ ì˜ˆì‹œ ê²Œì‹œê¸€)
    test_url = "https://www.fmkorea.com/8475910237"
    
    print(f"ğŸ” FMKorea ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“„ í…ŒìŠ¤íŠ¸ URL: {test_url}")
    print("-" * 50)
    
    try:
        # ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        scraper = FMKoreaScraper()
        
        # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        print("â³ ìŠ¤í¬ë˜í•‘ ì§„í–‰ ì¤‘...")
        result = await scraper.scrape_post(test_url)
        
        if not result:
            print("âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: ë¹ˆ ê²°ê³¼ ë°˜í™˜")
            return
            
        print("âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ!")
        print("-" * 50)
        
        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“Š ìŠ¤í¬ë˜í•‘ ê²°ê³¼:")
        print(f"ê²Œì‹œê¸€ ID: {result.get('post_id', 'N/A')}")
        
        metadata = result.get('metadata', {})
        print(f"ì œëª©: {metadata.get('title', 'N/A')}")
        print(f"ì‘ì„±ì: {metadata.get('author', 'N/A')}")
        print(f"ì‘ì„±ì¼: {metadata.get('date', 'N/A')}")
        print(f"ì¡°íšŒìˆ˜: {metadata.get('view_count', 0)}")
        print(f"ì¶”ì²œìˆ˜: {metadata.get('up_count', 0)}")
        print(f"ëŒ“ê¸€ìˆ˜: {metadata.get('comment_count', 0)}")
        print(f"ì¹´í…Œê³ ë¦¬: {metadata.get('category', 'N/A')}")
        
        content = result.get('content', [])
        print(f"ë³¸ë¬¸ ìš”ì†Œ ìˆ˜: {len(content)}")
        
        comments = result.get('comments', [])
        print(f"ëŒ“ê¸€ ìˆ˜: {len(comments)}")
        
        print("-" * 50)
        
        # ë³¸ë¬¸ ë‚´ìš© ì¼ë¶€ ì¶œë ¥
        if content:
            print("ğŸ“ ë³¸ë¬¸ ë‚´ìš© (ì²˜ìŒ 3ê°œ ìš”ì†Œ):")
            for i, item in enumerate(content[:3]):
                print(f"  {i+1}. {item['type']}: {str(item['data'])[:100]}...")
        
        # ëŒ“ê¸€ ì¼ë¶€ ì¶œë ¥
        if comments:
            print("ğŸ’¬ ëŒ“ê¸€ (ì²˜ìŒ 2ê°œ):")
            for i, comment in enumerate(comments[:2]):
                print(f"  {i+1}. {comment.get('author', 'N/A')}: {comment.get('content', 'N/A')[:50]}...")
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = "fmkorea_scraping_result.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return result
        
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return None

async def test_multiple_posts():
    """ì—¬ëŸ¬ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    
    # FMKorea ì •ì¹˜ ê²Œì‹œíŒ ì²« í˜ì´ì§€ì—ì„œ ëª‡ ê°œ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸
    test_urls = [
        "https://www.fmkorea.com/8475910237",  # ì œê³µëœ ì˜ˆì‹œ
        # ì¶”ê°€ URLë“¤ì€ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²Œì‹œê¸€ë¡œ êµì²´ í•„ìš”
    ]
    
    results = []
    
    for i, url in enumerate(test_urls, 1):
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ {i}/{len(test_urls)}: {url}")
        
        try:
            result = await scrape_and_save(url)
            if result:
                results.append(result)
                print(f"âœ… ì„±ê³µ: {result.get('metadata', {}).get('title', 'N/A')}")
            else:
                print("âŒ ì‹¤íŒ¨: ë¹ˆ ê²°ê³¼")
                
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            
        # ìš”ì²­ ê°„ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
        await asyncio.sleep(2)
    
    print(f"\nğŸ“Š ì „ì²´ ê²°ê³¼: {len(results)}/{len(test_urls)} ì„±ê³µ")
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    if results:
        with open("fmkorea_multiple_results.json", 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print("ğŸ’¾ ì „ì²´ ê²°ê³¼ê°€ fmkorea_multiple_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return results

if __name__ == "__main__":
    print("ğŸš€ FMKorea ìŠ¤í¬ë˜í¼ ìˆ˜ë™ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ë‹¨ì¼ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸
    result = asyncio.run(test_scraper())
    
    if result:
        print("\n" + "=" * 50)
        print("ğŸ¯ ë‹¨ì¼ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
        # ì‚¬ìš©ìì—ê²Œ ë‹¤ì¤‘ í…ŒìŠ¤íŠ¸ ì—¬ë¶€ í™•ì¸
        # response = input("\nì—¬ëŸ¬ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        # if response.lower() in ['y', 'yes']:
        #     print("\nğŸ”„ ë‹¤ì¤‘ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        #     asyncio.run(test_multiple_posts())
    else:
        print("\nâŒ ë‹¨ì¼ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1) 