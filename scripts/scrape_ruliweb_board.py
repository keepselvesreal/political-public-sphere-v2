"""
ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ë° MongoDB ì €ì¥ ìŠ¤í¬ë¦½íŠ¸

ëª©ì°¨:
- MongoDB ì—°ê²° ì„¤ì • (ë¼ì¸ 1-30)
- ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ í•¨ìˆ˜ (ë¼ì¸ 31-80)
- ë°ì´í„° ì €ì¥ ë° ë³€í™˜ í•¨ìˆ˜ (ë¼ì¸ 81-120)
- ë©”ì¸ ì‹¤í–‰ ë¡œì§ (ë¼ì¸ 121-150)

ì‘ì„±ì: AI Assistant
ì‘ì„±ì¼: 2025-01-28
ëª©ì : ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ë°ì´í„°ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ community_posts ì»¬ë ‰ì…˜ì— ì €ì¥
"""

import asyncio
import sys
import os
from datetime import datetime
from typing import List, Dict
import pytz

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from scraping.scrapers.ruliweb_scraper import ImprovedRuliwebScraper
import pymongo
from loguru import logger

# MongoDB ì—°ê²° ì„¤ì •
MONGODB_URI = 'mongodb+srv://nadle:miQXsXpzayvMQAzE@cluster0.bh7mhfi.mongodb.net/political_public_sphere'
DATABASE_NAME = 'political_public_sphere'
COLLECTION_NAME = 'community_posts'

# í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
KST = pytz.timezone('Asia/Seoul')

# ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ URL (ì •ì¹˜ ê´€ë ¨ ê²Œì‹œíŒ)
RULIWEB_BOARD_URLS = [
    'https://bbs.ruliweb.com/community/board/300143',  # ì •ì¹˜ ê²Œì‹œíŒ
    'https://bbs.ruliweb.com/community/board/300148',  # ì‚¬íšŒ ê²Œì‹œíŒ
]

async def connect_mongodb():
    """MongoDB ì—°ê²°"""
    try:
        client = pymongo.MongoClient(MONGODB_URI)
        db = client[DATABASE_NAME]
        collection = db[COLLECTION_NAME]
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        client.admin.command('ping')
        logger.info("âœ… MongoDB ì—°ê²° ì„±ê³µ")
        
        return client, db, collection
    except Exception as e:
        logger.error(f"ğŸ’¥ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

def transform_ruliweb_post_to_community_format(post_data: Dict) -> Dict:
    """
    ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ë°ì´í„°ë¥¼ community_posts í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        post_data: ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ ê²°ê³¼
    
    Returns:
        Dict: community_posts í˜•ì‹ ë°ì´í„°
    """
    try:
        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        post_id = post_data.get('id', post_data.get('post_id', 'unknown'))
        title = post_data.get('title', 'ì œëª© ì—†ìŒ')
        author = post_data.get('author', 'ìµëª…')
        created_time = post_data.get('date', post_data.get('created_time', ''))
        post_url = post_data.get('url', post_data.get('post_url', ''))
        
        # ë©”íŠ¸ë¦­ ë°ì´í„° ì¶”ì¶œ
        view_count = post_data.get('views', post_data.get('view_count', 0))
        recommend_count = post_data.get('recommendations', post_data.get('recommend_count', 0))
        reply_count = post_data.get('reply_count', 0)
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        category = post_data.get('category', 'ì¼ë°˜')
        
        # í˜„ì¬ ì‹œê°„
        now = datetime.now(KST)
        
        # community_posts í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        community_post = {
            'post_id': str(post_id),
            'site': 'ruliweb',
            'post_url': post_url,
            'scraped_at': now.isoformat(),
            'metadata': {
                'title': title,
                'author': author,
                'date': created_time,
                'created_at': created_time,
                'category': category,
                'view_count': int(view_count) if isinstance(view_count, (int, str)) and str(view_count).isdigit() else 0,
                'like_count': int(recommend_count) if isinstance(recommend_count, (int, str)) and str(recommend_count).isdigit() else 0,
                'comment_count': int(reply_count) if isinstance(reply_count, (int, str)) and str(reply_count).isdigit() else 0,
                'recommendations': int(recommend_count) if isinstance(recommend_count, (int, str)) and str(recommend_count).isdigit() else 0,
                'views': int(view_count) if isinstance(view_count, (int, str)) and str(view_count).isdigit() else 0,
            },
            'content': [
                {
                    'type': 'text',
                    'order': 0,
                    'text': title,
                    'extracted_at': now.isoformat()
                }
            ],
            'comments': [],
            'created_at': now.isoformat(),
            'updated_at': now.isoformat()
        }
        
        return community_post
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None

async def scrape_ruliweb_boards():
    """ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ì‹¤í–‰"""
    try:
        logger.info("ğŸš€ ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
        
        # MongoDB ì—°ê²°
        client, db, collection = await connect_mongodb()
        
        # ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
        async with ImprovedRuliwebScraper() as scraper:
            all_posts = []
            
            for board_url in RULIWEB_BOARD_URLS:
                try:
                    logger.info(f"ğŸ“‹ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {board_url}")
                    
                    # ê²Œì‹œíŒ ì²« í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
                    posts = await scraper.extract_board_list(board_url, page=1)
                    
                    if posts:
                        logger.info(f"âœ… {len(posts)}ê°œ ê²Œì‹œê¸€ ë°œê²¬")
                        all_posts.extend(posts)
                    else:
                        logger.warning(f"âš ï¸ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {board_url}")
                    
                    # ìš”ì²­ ê°„ ëŒ€ê¸°
                    await asyncio.sleep(2)
                    
                except Exception as e:
                    logger.error(f"ğŸ’¥ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ({board_url}): {e}")
                    continue
            
            if not all_posts:
                logger.warning("âš ï¸ ìŠ¤í¬ë˜í•‘ëœ ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"ğŸ“Š ì´ {len(all_posts)}ê°œ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ")
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            saved_count = 0
            for post_data in all_posts:
                try:
                    # community_posts í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                    community_post = transform_ruliweb_post_to_community_format(post_data)
                    
                    if community_post:
                        # ì¤‘ë³µ í™•ì¸ (post_idì™€ site ê¸°ì¤€)
                        existing = collection.find_one({
                            'post_id': community_post['post_id'],
                            'site': 'ruliweb'
                        })
                        
                        if existing:
                            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                            collection.update_one(
                                {'_id': existing['_id']},
                                {'$set': {
                                    'metadata': community_post['metadata'],
                                    'updated_at': community_post['updated_at']
                                }}
                            )
                            logger.debug(f"ğŸ”„ ê²Œì‹œê¸€ ì—…ë°ì´íŠ¸: {community_post['post_id']}")
                        else:
                            # ìƒˆ ë°ì´í„° ì‚½ì…
                            collection.insert_one(community_post)
                            saved_count += 1
                            logger.debug(f"ğŸ’¾ ìƒˆ ê²Œì‹œê¸€ ì €ì¥: {community_post['post_id']}")
                    
                except Exception as e:
                    logger.error(f"ğŸ’¥ ê²Œì‹œê¸€ ì €ì¥ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {saved_count}ê°œ ìƒˆ ê²Œì‹œê¸€ ì €ì¥")
            
    except Exception as e:
        logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        raise
    finally:
        # MongoDB ì—°ê²° ì¢…ë£Œ
        if 'client' in locals():
            client.close()

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        await scrape_ruliweb_boards()
        logger.info("ğŸ‰ ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ ì‘ì—… ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ğŸ’¥ ìŠ¤í¬ë˜í•‘ ì‘ì—… ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    # ë¡œê·¸ ì„¤ì •
    logger.add("logs/ruliweb_scraping.log", rotation="1 day", retention="7 days")
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main()) 