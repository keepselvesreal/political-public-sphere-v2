"""
ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í†µí•© í…ŒìŠ¤íŠ¸

ì£¼ìš” í…ŒìŠ¤íŠ¸:
- FMì½”ë¦¬ì•„ ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ (line 20-60)
- ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ (line 62-100)
- ì§€í‘œë³„ ì„ ë³„ ë¡œì§ ê²€ì¦ (line 102-150)
- CommunityPost ëª¨ë¸ ì¶œë ¥ ê²€ì¦ (line 152-200)

ì‘ì„±ì: AI Assistant
ì‘ì„±ì¼: 2025-01-28
ëª©ì : TDD ë°©ì‹ìœ¼ë¡œ ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ê¸°ëŠ¥ ê²€ì¦
"""

import pytest
import asyncio
from typing import Dict, List

# ì‹¤ì œ êµ¬í˜„ëœ ëª¨ë“ˆë“¤ import
from scraping.scrapers.fmkorea_scraper_v2 import FMKoreaScraper
from scraping.scrapers.ruliweb_scraper_v2 import RuliwebScraper
from scripts.community_post_utils import SelectionCriteria


class TestFMKoreaScraping:
    """FMì½”ë¦¬ì•„ ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_fmkorea_board_scraping(self):
        """FMì½”ë¦¬ì•„ ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
        # FMì½”ë¦¬ì•„ ì •ì¹˜ ê²Œì‹œíŒ URL (ì‹¤ì œ í…ŒìŠ¤íŠ¸ìš©)
        board_url = "https://www.fmkorea.com/index.php?mid=politics"
        
        async with FMKoreaScraper() as scraper:
            # ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘
            posts = await scraper.scrape_board_list(board_url)
            
            # ê¸°ë³¸ ê²€ì¦
            assert isinstance(posts, list)
            assert len(posts) > 0, "ê²Œì‹œê¸€ì´ í•˜ë‚˜ë„ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            
            # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ êµ¬ì¡° ê²€ì¦
            first_post = posts[0]
            required_fields = ['post_id', 'title', 'post_url', 'like_count', 'comment_count', 'view_count']
            
            for field in required_fields:
                assert field in first_post, f"í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            assert isinstance(first_post['post_id'], str)
            assert isinstance(first_post['title'], str)
            assert isinstance(first_post['post_url'], str)
            assert isinstance(first_post['like_count'], int)
            assert isinstance(first_post['comment_count'], int)
            assert isinstance(first_post['view_count'], int)
            
            # URL í˜•ì‹ ê²€ì¦
            assert first_post['post_url'].startswith('https://www.fmkorea.com')
            
            print(f"âœ… FMì½”ë¦¬ì•„ ê²Œì‹œê¸€ {len(posts)}ê°œ ì¶”ì¶œ ì„±ê³µ")
            print(f"ğŸ“ ì²« ë²ˆì§¸ ê²Œì‹œê¸€: {first_post['title'][:30]}...")
    
    @pytest.mark.asyncio
    async def test_fmkorea_post_selection(self):
        """FMì½”ë¦¬ì•„ ì§€í‘œë³„ ì„ ë³„ í…ŒìŠ¤íŠ¸"""
        board_url = "https://www.fmkorea.com/index.php?mid=politics"
        
        async with FMKoreaScraper() as scraper:
            # ì§€í‘œë³„ ì„ ë³„ ìŠ¤í¬ë˜í•‘
            selected_posts = await scraper.scrape_board_with_selection(board_url, criteria_count=3)
            
            # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
            assert isinstance(selected_posts, dict)
            expected_criteria = ['likes', 'comments', 'views']
            
            for criteria in expected_criteria:
                assert criteria in selected_posts, f"ì„ ë³„ ê¸°ì¤€ '{criteria}'ê°€ ì—†ìŠµë‹ˆë‹¤"
                assert isinstance(selected_posts[criteria], list)
                assert len(selected_posts[criteria]) <= 3, f"{criteria} ê¸°ì¤€ ê²Œì‹œê¸€ì´ 3ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
            
            # ì¤‘ë³µ ì œê±° ê²€ì¦
            all_post_ids = set()
            for criteria, posts in selected_posts.items():
                for post in posts:
                    post_id = post['post_id']
                    assert post_id not in all_post_ids, f"ì¤‘ë³µëœ ê²Œì‹œê¸€ ID ë°œê²¬: {post_id}"
                    all_post_ids.add(post_id)
            
            print(f"âœ… FMì½”ë¦¬ì•„ ì§€í‘œë³„ ì„ ë³„ ì™„ë£Œ:")
            for criteria, posts in selected_posts.items():
                print(f"  - {criteria}: {len(posts)}ê°œ")


class TestRuliwebScraping:
    """ë£¨ë¦¬ì›¹ ì‹¤ì œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_ruliweb_board_scraping(self):
        """ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
        # ë£¨ë¦¬ì›¹ ì •ì¹˜ ê²Œì‹œíŒ URL (ì‹¤ì œ í…ŒìŠ¤íŠ¸ìš©)
        board_url = "https://bbs.ruliweb.com/community/board/300143"
        
        async with RuliwebScraper() as scraper:
            # ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘
            posts = await scraper.scrape_board_list(board_url)
            
            # ê¸°ë³¸ ê²€ì¦
            assert isinstance(posts, list)
            assert len(posts) > 0, "ê²Œì‹œê¸€ì´ í•˜ë‚˜ë„ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            
            # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ êµ¬ì¡° ê²€ì¦
            first_post = posts[0]
            required_fields = ['post_id', 'title', 'post_url', 'like_count', 'comment_count', 'view_count']
            
            for field in required_fields:
                assert field in first_post, f"í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            assert isinstance(first_post['post_id'], str)
            assert isinstance(first_post['title'], str)
            assert isinstance(first_post['post_url'], str)
            assert isinstance(first_post['like_count'], int)
            assert isinstance(first_post['comment_count'], int)
            assert isinstance(first_post['view_count'], int)
            
            # URL í˜•ì‹ ê²€ì¦
            assert first_post['post_url'].startswith('https://bbs.ruliweb.com')
            
            print(f"âœ… ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ {len(posts)}ê°œ ì¶”ì¶œ ì„±ê³µ")
            print(f"ğŸ“ ì²« ë²ˆì§¸ ê²Œì‹œê¸€: {first_post['title'][:30]}...")
    
    @pytest.mark.asyncio
    async def test_ruliweb_post_selection(self):
        """ë£¨ë¦¬ì›¹ ì§€í‘œë³„ ì„ ë³„ í…ŒìŠ¤íŠ¸"""
        board_url = "https://bbs.ruliweb.com/community/board/300143"
        
        async with RuliwebScraper() as scraper:
            # ì§€í‘œë³„ ì„ ë³„ ìŠ¤í¬ë˜í•‘
            selected_posts = await scraper.scrape_board_with_selection(board_url, criteria_count=3)
            
            # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
            assert isinstance(selected_posts, dict)
            expected_criteria = ['likes', 'comments', 'views']
            
            for criteria in expected_criteria:
                assert criteria in selected_posts, f"ì„ ë³„ ê¸°ì¤€ '{criteria}'ê°€ ì—†ìŠµë‹ˆë‹¤"
                assert isinstance(selected_posts[criteria], list)
                assert len(selected_posts[criteria]) <= 3, f"{criteria} ê¸°ì¤€ ê²Œì‹œê¸€ì´ 3ê°œë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤"
            
            # ì¤‘ë³µ ì œê±° ê²€ì¦
            all_post_ids = set()
            for criteria, posts in selected_posts.items():
                for post in posts:
                    post_id = post['post_id']
                    assert post_id not in all_post_ids, f"ì¤‘ë³µëœ ê²Œì‹œê¸€ ID ë°œê²¬: {post_id}"
                    all_post_ids.add(post_id)
            
            print(f"âœ… ë£¨ë¦¬ì›¹ ì§€í‘œë³„ ì„ ë³„ ì™„ë£Œ:")
            for criteria, posts in selected_posts.items():
                print(f"  - {criteria}: {len(posts)}ê°œ")


class TestCommunityPostIntegration:
    """CommunityPost ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.asyncio
    async def test_fmkorea_post_detail_scraping(self):
        """FMì½”ë¦¬ì•„ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
        # ë¨¼ì € ê²Œì‹œíŒì—ì„œ ê²Œì‹œê¸€ URL í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
        board_url = "https://www.fmkorea.com/index.php?mid=politics"
        
        async with FMKoreaScraper() as scraper:
            posts = await scraper.scrape_board_list(board_url)
            assert len(posts) > 0, "í…ŒìŠ¤íŠ¸í•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤"
            
            # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘
            test_post_url = posts[0]['post_url']
            post_detail = await scraper.scrape_post_detail(test_post_url)
            
            # CommunityPost ëª¨ë¸ êµ¬ì¡° ê²€ì¦
            required_fields = ['post_id', 'post_url', 'scraped_at', 'metadata', 'content', 'comments']
            for field in required_fields:
                assert field in post_detail, f"CommunityPost í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì¡° ê²€ì¦
            metadata = post_detail['metadata']
            metadata_fields = ['title', 'author', 'view_count', 'like_count', 'comment_count']
            for field in metadata_fields:
                assert field in metadata, f"ë©”íƒ€ë°ì´í„° í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ì½˜í…ì¸  êµ¬ì¡° ê²€ì¦
            content = post_detail['content']
            assert isinstance(content, list), "ì½˜í…ì¸ ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
            
            if content:  # ì½˜í…ì¸ ê°€ ìˆëŠ” ê²½ìš°
                first_content = content[0]
                assert 'type' in first_content, "ì½˜í…ì¸ ì— type í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
                assert 'order' in first_content, "ì½˜í…ì¸ ì— order í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
                assert 'data' in first_content, "ì½˜í…ì¸ ì— data í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ëŒ“ê¸€ êµ¬ì¡° ê²€ì¦
            comments = post_detail['comments']
            assert isinstance(comments, list), "ëŒ“ê¸€ì€ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
            
            print(f"âœ… FMì½”ë¦¬ì•„ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ ì„±ê³µ")
            print(f"ğŸ“ ì œëª©: {metadata['title'][:50]}...")
            print(f"ğŸ“Š ì½˜í…ì¸ : {len(content)}ê°œ, ëŒ“ê¸€: {len(comments)}ê°œ")
    
    @pytest.mark.asyncio
    async def test_ruliweb_post_detail_scraping(self):
        """ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
        # ë¨¼ì € ê²Œì‹œíŒì—ì„œ ê²Œì‹œê¸€ URL í•˜ë‚˜ ê°€ì ¸ì˜¤ê¸°
        board_url = "https://bbs.ruliweb.com/community/board/300143"
        
        async with RuliwebScraper() as scraper:
            posts = await scraper.scrape_board_list(board_url)
            assert len(posts) > 0, "í…ŒìŠ¤íŠ¸í•  ê²Œì‹œê¸€ì´ ì—†ìŠµë‹ˆë‹¤"
            
            # ì²« ë²ˆì§¸ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘
            test_post_url = posts[0]['post_url']
            post_detail = await scraper.scrape_post_detail(test_post_url)
            
            # CommunityPost ëª¨ë¸ êµ¬ì¡° ê²€ì¦
            required_fields = ['post_id', 'post_url', 'scraped_at', 'metadata', 'content', 'comments']
            for field in required_fields:
                assert field in post_detail, f"CommunityPost í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì¡° ê²€ì¦
            metadata = post_detail['metadata']
            metadata_fields = ['title', 'author', 'view_count', 'like_count', 'comment_count']
            for field in metadata_fields:
                assert field in metadata, f"ë©”íƒ€ë°ì´í„° í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤"
            
            # ì½˜í…ì¸  êµ¬ì¡° ê²€ì¦
            content = post_detail['content']
            assert isinstance(content, list), "ì½˜í…ì¸ ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
            
            # ëŒ“ê¸€ êµ¬ì¡° ê²€ì¦ (ë£¨ë¦¬ì›¹ íŠ¹í™”: ì´ë¯¸ì§€ í¬í•¨)
            comments = post_detail['comments']
            assert isinstance(comments, list), "ëŒ“ê¸€ì€ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
            
            if comments:  # ëŒ“ê¸€ì´ ìˆëŠ” ê²½ìš°
                first_comment = comments[0]
                assert 'images' in first_comment, "ë£¨ë¦¬ì›¹ ëŒ“ê¸€ì— images í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤"
                assert isinstance(first_comment['images'], list), "ëŒ“ê¸€ ì´ë¯¸ì§€ëŠ” ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤"
            
            print(f"âœ… ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ ì„±ê³µ")
            print(f"ğŸ“ ì œëª©: {metadata['title'][:50]}...")
            print(f"ğŸ“Š ì½˜í…ì¸ : {len(content)}ê°œ, ëŒ“ê¸€: {len(comments)}ê°œ")


if __name__ == "__main__":
    # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ
    import asyncio
    
    async def run_quick_test():
        """ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ FMì½”ë¦¬ì•„ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        async with FMKoreaScraper() as scraper:
            board_url = "https://www.fmkorea.com/index.php?mid=politics"
            posts = await scraper.scrape_board_list(board_url)
            print(f"âœ… {len(posts)}ê°œ ê²Œì‹œê¸€ ì¶”ì¶œ ì™„ë£Œ")
            
            if posts:
                print(f"ğŸ“ ì²« ë²ˆì§¸ ê²Œì‹œê¸€: {posts[0]['title'][:30]}...")
    
    # asyncio.run(run_quick_test()) 