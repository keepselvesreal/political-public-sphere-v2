"""
API í†µí•© í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)

ì£¼ìš” í…ŒìŠ¤íŠ¸:
- ìŠ¤í¬ë˜í•‘ ë°ì´í„° â†’ API í˜•ì‹ ë³€í™˜ í…ŒìŠ¤íŠ¸ (line 20-80)
- API ì‘ë‹µ í˜•ì‹ ê²€ì¦ (line 82-120)
- ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ (line 122-160)

ì‘ì„±ì: AI Assistant
ì‘ì„±ì¼: 2025-01-28
ëª©ì : API ë°ì´í„° ë³€í™˜ ë¡œì§ ê²€ì¦
"""

import pytest
import json
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from api.community_posts_api import load_latest_scraped_data, convert_scraped_to_api_format


class TestAPIIntegration:
    """API í†µí•© í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def scraped_data(self):
        """ì‹¤ì œ ìŠ¤í¬ë˜í•‘ëœ ë°ì´í„° ë¡œë“œ"""
        return load_latest_scraped_data()
    
    def test_load_scraped_data(self, scraped_data):
        """ìŠ¤í¬ë˜í•‘ ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸"""
        assert isinstance(scraped_data, dict)
        assert "fmkorea" in scraped_data
        assert "ruliweb" in scraped_data
        
        # ê° ì‚¬ì´íŠ¸ ë°ì´í„° êµ¬ì¡° í™•ì¸
        for site in ["fmkorea", "ruliweb"]:
            site_data = scraped_data[site]
            assert "board_posts" in site_data
            assert "detailed_posts" in site_data
            assert isinstance(site_data["board_posts"], list)
            assert isinstance(site_data["detailed_posts"], list)
    
    def test_convert_to_api_format(self, scraped_data):
        """ìŠ¤í¬ë˜í•‘ ë°ì´í„° â†’ API í˜•ì‹ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
        assert isinstance(api_data, dict)
        assert "likesPerView" in api_data
        assert "commentsPerView" in api_data
        assert "viewsPerHour" in api_data
        assert "allPosts" in api_data
        
        # ê° ì¹´í…Œê³ ë¦¬ê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
        for key in ["likesPerView", "commentsPerView", "viewsPerHour", "allPosts"]:
            assert isinstance(api_data[key], list)
    
    def test_api_post_structure(self, scraped_data):
        """API ê²Œì‹œê¸€ êµ¬ì¡° í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        if api_data["allPosts"]:
            post = api_data["allPosts"][0]
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = [
                "_id", "post_id", "community", "site", "title", "author",
                "created_at", "views", "likes", "dislikes", "comments_count",
                "url", "top_likes", "top_comments", "top_views"
            ]
            
            for field in required_fields:
                assert field in post, f"API ê²Œì‹œê¸€ì— {field} í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ë°ì´í„° íƒ€ì… í™•ì¸
            assert isinstance(post["_id"], str)
            assert isinstance(post["post_id"], str)
            assert isinstance(post["community"], str)
            assert isinstance(post["site"], str)
            assert isinstance(post["title"], str)
            assert isinstance(post["author"], str)
            assert isinstance(post["views"], int)
            assert isinstance(post["likes"], int)
            assert isinstance(post["dislikes"], int)
            assert isinstance(post["comments_count"], int)
            assert isinstance(post["url"], str)
            assert isinstance(post["top_likes"], bool)
            assert isinstance(post["top_comments"], bool)
            assert isinstance(post["top_views"], bool)
    
    def test_metric_classification(self, scraped_data):
        """ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # ë©”íŠ¸ë¦­ë³„ ë¶„ë¥˜ ë¡œì§ í™•ì¸
        for post in api_data["likesPerView"]:
            assert post["top_likes"] == True, "likesPerViewì— top_likesê°€ Falseì¸ ê²Œì‹œê¸€ì´ ìˆìŠµë‹ˆë‹¤."
        
        for post in api_data["commentsPerView"]:
            assert post["top_comments"] == True, "commentsPerViewì— top_commentsê°€ Falseì¸ ê²Œì‹œê¸€ì´ ìˆìŠµë‹ˆë‹¤."
        
        for post in api_data["viewsPerHour"]:
            assert post["top_views"] == True, "viewsPerHourì— top_viewsê°€ Falseì¸ ê²Œì‹œê¸€ì´ ìˆìŠµë‹ˆë‹¤."
    
    def test_site_specific_conversion(self, scraped_data):
        """ì‚¬ì´íŠ¸ë³„ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # ì‚¬ì´íŠ¸ë³„ ê²Œì‹œê¸€ ë¶„ë¦¬
        fmkorea_posts = [p for p in api_data["allPosts"] if p["site"] == "fmkorea"]
        ruliweb_posts = [p for p in api_data["allPosts"] if p["site"] == "ruliweb"]
        
        # FMì½”ë¦¬ì•„ ê²Œì‹œê¸€ íŠ¹ì„± í™•ì¸
        for post in fmkorea_posts:
            assert post["community"] == "fmkorea"
            assert post["site"] == "fmkorea"
            assert post["dislikes"] == 0   # FMì½”ë¦¬ì•„ëŠ” ë¹„ì¶”ì²œ ì—†ìŒ
        
        # ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ íŠ¹ì„± í™•ì¸
        for post in ruliweb_posts:
            assert post["community"] == "ruliweb"
            assert post["site"] == "ruliweb"
            assert post["dislikes"] == 0   # ë£¨ë¦¬ì›¹ë„ ë¹„ì¶”ì²œ ì—†ìŒ
    
    def test_metric_thresholds(self, scraped_data):
        """ë©”íŠ¸ë¦­ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # FMì½”ë¦¬ì•„ ì„ê³„ê°’ í™•ì¸
        fmkorea_posts = [p for p in api_data["allPosts"] if p["site"] == "fmkorea"]
        for post in fmkorea_posts:
            if post["top_likes"]:
                assert post["likes"] > 50, f"FMì½”ë¦¬ì•„ top_likes ì„ê³„ê°’ ì˜¤ë¥˜: {post['likes']}"
            if post["top_comments"]:
                assert post["comments_count"] > 10, f"FMì½”ë¦¬ì•„ top_comments ì„ê³„ê°’ ì˜¤ë¥˜: {post['comments_count']}"
            if post["top_views"]:
                assert post["views"] > 1000, f"FMì½”ë¦¬ì•„ top_views ì„ê³„ê°’ ì˜¤ë¥˜: {post['views']}"
        
        # ë£¨ë¦¬ì›¹ ì„ê³„ê°’ í™•ì¸
        ruliweb_posts = [p for p in api_data["allPosts"] if p["site"] == "ruliweb"]
        for post in ruliweb_posts:
            if post["top_likes"]:
                assert post["likes"] > 20, f"ë£¨ë¦¬ì›¹ top_likes ì„ê³„ê°’ ì˜¤ë¥˜: {post['likes']}"
            if post["top_comments"]:
                assert post["comments_count"] > 5, f"ë£¨ë¦¬ì›¹ top_comments ì„ê³„ê°’ ì˜¤ë¥˜: {post['comments_count']}"
            if post["top_views"]:
                assert post["views"] > 500, f"ë£¨ë¦¬ì›¹ top_views ì„ê³„ê°’ ì˜¤ë¥˜: {post['views']}"
    
    def test_data_consistency(self, scraped_data):
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # ì „ì²´ ê²Œì‹œê¸€ ìˆ˜ì™€ ë©”íŠ¸ë¦­ë³„ ê²Œì‹œê¸€ ìˆ˜ ë¹„êµ
        total_posts = len(api_data["allPosts"])
        metric_posts = (len(api_data["likesPerView"]) + 
                       len(api_data["commentsPerView"]) + 
                       len(api_data["viewsPerHour"]))
        
        # ë©”íŠ¸ë¦­ë³„ ê²Œì‹œê¸€ì€ ì „ì²´ ê²Œì‹œê¸€ì˜ ë¶€ë¶„ì§‘í•©ì´ì–´ì•¼ í•¨
        assert metric_posts <= total_posts * 3  # ì¤‘ë³µ ê°€ëŠ¥í•˜ë¯€ë¡œ 3ë°°ê¹Œì§€ í—ˆìš©
        
        # ëª¨ë“  ë©”íŠ¸ë¦­ ê²Œì‹œê¸€ì´ ì „ì²´ ê²Œì‹œê¸€ì— í¬í•¨ë˜ì–´ì•¼ í•¨
        all_post_ids = {p["_id"] for p in api_data["allPosts"]}
        
        for post in api_data["likesPerView"]:
            assert post["_id"] in all_post_ids, "likesPerView ê²Œì‹œê¸€ì´ allPostsì— ì—†ìŠµë‹ˆë‹¤."
        
        for post in api_data["commentsPerView"]:
            assert post["_id"] in all_post_ids, "commentsPerView ê²Œì‹œê¸€ì´ allPostsì— ì—†ìŠµë‹ˆë‹¤."
        
        for post in api_data["viewsPerHour"]:
            assert post["_id"] in all_post_ids, "viewsPerHour ê²Œì‹œê¸€ì´ allPostsì— ì—†ìŠµë‹ˆë‹¤."
    
    def test_api_response_simulation(self, scraped_data):
        """API ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""
        api_data = convert_scraped_to_api_format(scraped_data)
        
        # API ì‘ë‹µ í˜•ì‹ ì‹œë®¬ë ˆì´ì…˜
        def simulate_api_response(metric=None, site=None, limit=50):
            if metric == "likes":
                posts = api_data["likesPerView"]
            elif metric == "comments":
                posts = api_data["commentsPerView"]
            elif metric == "views":
                posts = api_data["viewsPerHour"]
            else:
                posts = api_data["allPosts"]
            
            if site:
                posts = [p for p in posts if p["site"] == site]
            
            posts = posts[:limit]
            
            return {
                "success": True,
                "data": {
                    "likesPerView": api_data["likesPerView"][:limit] if metric != "likes" else posts,
                    "commentsPerView": api_data["commentsPerView"][:limit] if metric != "comments" else posts,
                    "viewsPerHour": api_data["viewsPerHour"][:limit] if metric != "views" else posts,
                    "total": len(posts),
                    "filters": {
                        "metric": metric,
                        "site": site,
                        "limit": limit
                    }
                }
            }
        
        # ë‹¤ì–‘í•œ í•„í„° ì¡°ê±´ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        test_cases = [
            {"metric": None, "site": None, "limit": 50},
            {"metric": "likes", "site": None, "limit": 10},
            {"metric": "comments", "site": "fmkorea", "limit": 5},
            {"metric": "views", "site": "ruliweb", "limit": 20}
        ]
        
        for case in test_cases:
            response = simulate_api_response(**case)
            
            # ì‘ë‹µ êµ¬ì¡° í™•ì¸
            assert response["success"] == True
            assert "data" in response
            assert "total" in response["data"]
            assert "filters" in response["data"]
            
            # í•„í„° ì ìš© í™•ì¸
            assert response["data"]["filters"]["metric"] == case["metric"]
            assert response["data"]["filters"]["site"] == case["site"]
            assert response["data"]["filters"]["limit"] == case["limit"]
            
            # ê²°ê³¼ ê°œìˆ˜ í™•ì¸
            assert response["data"]["total"] <= case["limit"]


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥"""
    print("ğŸ§ª API í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸
    scraped_data = load_latest_scraped_data()
    print(f"âœ… ìŠ¤í¬ë˜í•‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"   - FMì½”ë¦¬ì•„ ê²Œì‹œê¸€: {len(scraped_data.get('fmkorea', {}).get('board_posts', []))}ê°œ")
    print(f"   - ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€: {len(scraped_data.get('ruliweb', {}).get('board_posts', []))}ê°œ")
    
    # API í˜•ì‹ ë³€í™˜ í…ŒìŠ¤íŠ¸
    api_data = convert_scraped_to_api_format(scraped_data)
    print(f"âœ… API í˜•ì‹ ë³€í™˜ ì™„ë£Œ")
    print(f"   - ì „ì²´ ê²Œì‹œê¸€: {len(api_data['allPosts'])}ê°œ")
    print(f"   - ì¶”ì²œë¥  ë†’ì€ ê²Œì‹œê¸€: {len(api_data['likesPerView'])}ê°œ")
    print(f"   - ëŒ“ê¸€ë¥  ë†’ì€ ê²Œì‹œê¸€: {len(api_data['commentsPerView'])}ê°œ")
    print(f"   - ì¡°íšŒìˆ˜ ë†’ì€ ê²Œì‹œê¸€: {len(api_data['viewsPerHour'])}ê°œ")
    
    # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    if api_data['allPosts']:
        sample_post = api_data['allPosts'][0]
        print(f"âœ… ìƒ˜í”Œ ê²Œì‹œê¸€:")
        print(f"   - ì œëª©: {sample_post['title'][:30]}...")
        print(f"   - ì‚¬ì´íŠ¸: {sample_post['site']}")
        print(f"   - ì¡°íšŒìˆ˜: {sample_post['views']:,}")
        print(f"   - ì¶”ì²œìˆ˜: {sample_post['likes']:,}")
        print(f"   - ëŒ“ê¸€ìˆ˜: {sample_post['comments_count']:,}")
    
    print("ğŸ‰ API í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main() 