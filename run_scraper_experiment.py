#!/usr/bin/env python3
"""
FMKorea ìŠ¤í¬ë˜í¼ ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ì‹¤ì‹œê°„ API ì—°ë™)
ì—…ê·¸ë ˆì´ë“œëœ ìŠ¤í¬ë˜í¼ë¡œ ì •ì¹˜ ê²Œì‹œíŒì„ ìŠ¤í¬ë˜í•‘í•˜ê³  ì‹¤í—˜ í˜ì´ì§€ì— ìë™ ì „ì†¡í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
import os
import json
from datetime import datetime

# ìŠ¤í¬ë˜í¼ ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'scraping', 'scrapers'))

from fmkorea_scraper_v3 import scrape_fmkorea_politics_page

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ FMKorea ìŠ¤í¬ë˜í¼ v3 ì‹¤í—˜ ì‹œì‘ (ì‹¤ì‹œê°„ API ì—°ë™)")
    print("=" * 70)
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ¯ ëŒ€ìƒ: https://www.fmkorea.com/politics")
    print("ğŸŒ ì‹¤í—˜ í˜ì´ì§€: http://localhost:3000/scraper-experiment")
    print("-" * 70)
    
    # ìŠ¤í¬ë˜í•‘ ì„¤ì • (API ì „ì†¡ í¬í•¨)
    config = {
        'headless': True,
        'slow_mo': 1000,  # 1ì´ˆ ì§€ì—°
        'wait_time': 2,   # í˜ì´ì§€ ë¡œë“œ í›„ 2ì´ˆ ëŒ€ê¸°
        'delay_between_requests': 3,  # ìš”ì²­ ê°„ 3ì´ˆ ê°„ê²©
        'timeout': 45000,  # 45ì´ˆ íƒ€ì„ì•„ì›ƒ
        'api_url': 'http://localhost:3000/api/scraper-data'  # API ì—”ë“œí¬ì¸íŠ¸
    }
    
    try:
        print("ğŸ” FMKorea ì •ì¹˜ ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
        
        # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
        results = await scrape_fmkorea_politics_page(config)
        
        if results:
            print(f"âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ! {len(results)}ê°œ ê²Œì‹œê¸€ ì¶”ì¶œ")
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print("\nğŸ“Š ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ìš”ì•½:")
            for i, post in enumerate(results, 1):
                metadata = post.get('metadata', {})
                print(f"  {i}. {metadata.get('title', 'N/A')[:50]}...")
                print(f"     ì‘ì„±ì: {metadata.get('author', 'N/A')}")
                print(f"     ì¡°íšŒìˆ˜: {metadata.get('view_count', 0):,}")
                print(f"     ì¶”ì²œìˆ˜: {metadata.get('up_count', 0):,}")
                print(f"     ëŒ“ê¸€ìˆ˜: {metadata.get('comment_count', 0):,}")
                print(f"     ì½˜í…ì¸ : {len(post.get('content', []))}ê°œ")
                print()
            
            # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"fmkorea_politics_experiment_{timestamp}.json"
            
            # JSON íŒŒì¼ë¡œ ì €ì¥ (ë°±ì—…ìš©)
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ë°±ì—… íŒŒì¼ì´ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸŒ ì‹¤í—˜ìš© í˜ì´ì§€ì—ì„œ ì‹¤ì‹œê°„ í™•ì¸: http://localhost:3000/scraper-experiment")
            print("ğŸ“± ì‹¤í—˜ í˜ì´ì§€ê°€ ìë™ìœ¼ë¡œ ê°±ì‹ ë©ë‹ˆë‹¤!")
            
        else:
            print("âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"âŒ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
    print("\n" + "=" * 70)
    print(f"â° ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ FMKorea ìŠ¤í¬ë˜í¼ v3 ì‹¤í—˜ ì™„ë£Œ")
    print("ğŸ’¡ ì‹¤í—˜ í˜ì´ì§€ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!")

if __name__ == "__main__":
    asyncio.run(main()) 