"""
ëª©ì°¨:
- ìƒˆë¡œìš´ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ (1-80ì¤„)
  - test_new_fmkorea_post: ìƒˆ ì—í¨ì½”ë¦¬ì•„ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘
  - test_new_ruliweb_post: ìƒˆ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘
  - main: í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í•¨ìˆ˜
"""

import asyncio
import sys
from pathlib import Path

# scrapers ëª¨ë“ˆ import
sys.path.append(str(Path(__file__).parent))

from scrapers.fmkorea_scraper import scrape_fmkorea_post, save_to_json
from scrapers.ruliweb_scraper import scrape_ruliweb_post

async def test_new_fmkorea_post():
    """ìƒˆë¡œìš´ ì—í¨ì½”ë¦¬ì•„ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    print("=== ìƒˆ ì—í¨ì½”ë¦¬ì•„ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ===")
    
    test_url = "https://www.fmkorea.com/8485697756"
    print(f"URL: {test_url}")
    
    try:
        result = await scrape_fmkorea_post(test_url)
        
        if result:
            print(f"âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ!")
            print(f"Post ID: {result['post_id']}")
            print(f"Community: {result['community']}")
            print(f"Title: {result['metadata']['title']}")
            print(f"Author: {result['metadata']['author']}")
            print(f"Date: {result['metadata']['date']}")
            print(f"View Count: {result['metadata']['view_count']}")
            print(f"Up Count: {result['metadata']['up_count']}")
            print(f"Comment Count: {result['metadata']['comment_count']}")
            print(f"Content Items: {len(result['content'])}")
            print(f"Comments: {len(result['comments'])}")
            
            # ëŒ“ê¸€ ìƒì„¸ ì •ë³´
            if result['comments']:
                print("\nëŒ“ê¸€ ìƒì„¸:")
                for i, comment in enumerate(result['comments'][:3]):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                    print(f"  {i+1}. {comment['author']}: {comment['content'][:50]}...")
                    print(f"     ë ˆë²¨: {comment['level']}, ëŒ€ëŒ“ê¸€: {comment['is_reply']}")
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            filename = f"fmkorea_{result['post_id']}_new.json"
            if save_to_json(result, filename):
                print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {filename}")
            
            return result
        else:
            print("âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

async def test_new_ruliweb_post():
    """ìƒˆë¡œìš´ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸"""
    print("\n=== ìƒˆ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ===")
    
    test_url = "https://bbs.ruliweb.com/community/board/300148/read/38077836"
    print(f"URL: {test_url}")
    
    try:
        result = await scrape_ruliweb_post(test_url)
        
        if result:
            print(f"âœ… ìŠ¤í¬ë˜í•‘ ì„±ê³µ!")
            print(f"Post ID: {result['post_id']}")
            print(f"Community: {result['community']}")
            print(f"Title: {result['metadata']['title']}")
            print(f"Author: {result['metadata']['author']}")
            print(f"Date: {result['metadata']['date']}")
            print(f"View Count: {result['metadata']['view_count']}")
            print(f"Up Count: {result['metadata']['up_count']}")
            print(f"Content Items: {len(result['content'])}")
            print(f"Comments: {len(result['comments'])}")
            
            # ëŒ“ê¸€ ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸
            image_count = sum(len(comment['media']) for comment in result['comments'])
            print(f"Comment Images: {image_count}")
            
            # ëŒ“ê¸€ ìƒì„¸ ì •ë³´
            if result['comments']:
                print("\nëŒ“ê¸€ ìƒì„¸:")
                for i, comment in enumerate(result['comments'][:3]):  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                    print(f"  {i+1}. {comment['author']}: {comment['content'][:50]}...")
                    print(f"     BEST: {comment.get('is_best', False)}, ì´ë¯¸ì§€: {len(comment['media'])}ê°œ")
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            from scrapers.ruliweb_scraper import save_to_json
            filename = f"ruliweb_{result['post_id']}_new.json"
            if save_to_json(result, filename):
                print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {filename}")
            
            return result
        else:
            print("âŒ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")
            return None
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # ì—í¨ì½”ë¦¬ì•„ ìƒˆ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸
    fmkorea_result = await test_new_fmkorea_post()
    
    # ë£¨ë¦¬ì›¹ ìƒˆ ê²Œì‹œê¸€ í…ŒìŠ¤íŠ¸
    ruliweb_result = await test_new_ruliweb_post()
    
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"ìƒˆ ì—í¨ì½”ë¦¬ì•„ ê²Œì‹œê¸€: {'âœ… ì„±ê³µ' if fmkorea_result else 'âŒ ì‹¤íŒ¨'}")
    print(f"ìƒˆ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€: {'âœ… ì„±ê³µ' if ruliweb_result else 'âŒ ì‹¤íŒ¨'}")
    
    if fmkorea_result:
        print(f"\nì—í¨ì½”ë¦¬ì•„ ê²°ê³¼:")
        print(f"  - ëŒ“ê¸€ ìˆ˜: {len(fmkorea_result['comments'])}")
        print(f"  - ë©”íƒ€ë°ì´í„° ì™„ì„±ë„: {len([v for v in fmkorea_result['metadata'].values() if v])}/7")
    
    if ruliweb_result:
        print(f"\në£¨ë¦¬ì›¹ ê²°ê³¼:")
        print(f"  - ëŒ“ê¸€ ìˆ˜: {len(ruliweb_result['comments'])}")
        print(f"  - ëŒ“ê¸€ ì´ë¯¸ì§€: {sum(len(c['media']) for c in ruliweb_result['comments'])}ê°œ")
    
    if fmkorea_result or ruliweb_result:
        print("\nğŸ‰ ìƒˆë¡œìš´ ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ìˆ˜ì •ëœ ìŠ¤í¬ë˜í¼ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ëª¨ë“  ìŠ¤í¬ë˜í•‘ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        print("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì´ë‚˜ ìŠ¤í¬ë˜í¼ ì½”ë“œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    asyncio.run(main()) 