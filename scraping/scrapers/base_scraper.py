"""
ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë˜í¼ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤

ì£¼ìš” ê¸°ëŠ¥:
- BaseCommunityScaper: ëª¨ë“  ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë˜í¼ì˜ ê¸°ë³¸ í´ë˜ìŠ¤ (line 20-80)
- í…œí”Œë¦¿ ë©”ì„œë“œ íŒ¨í„´ìœ¼ë¡œ ê³µí†µ ë¡œì§ ì •ì˜ (line 82-150)
- ì‚¬ì´íŠ¸ë³„ êµ¬í˜„ì´ í•„ìš”í•œ ì¶”ìƒ ë©”ì„œë“œ ì •ì˜ (line 152-200)
- ë¸Œë¼ìš°ì € ê´€ë¦¬ ë° ì—ëŸ¬ í•¸ë“¤ë§ ê³µí†µí™” (line 202-280)
- ê²Œì‹œê¸€ ì„ ë³„ ë° ì›Œí¬í”Œë¡œìš° í†µí•© (line 282-350)

ì‘ì„±ì: AI Assistant
ì‘ì„±ì¼: 2025-01-28
ëª©ì : ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë˜í¼ í†µì¼ì„± ë° ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
"""

import asyncio
import re
from abc import ABC, abstractmethod
from datetime import datetime
from typing import List, Dict, Optional, Any, Protocol
from urllib.parse import urljoin
import pytz

from playwright.async_api import async_playwright, Page, Browser
from playwright_stealth import stealth_async
from loguru import logger


class SiteConfig(Protocol):
    """ì‚¬ì´íŠ¸ë³„ ì„¤ì • í”„ë¡œí† ì½œ"""
    base_url: str
    selectors: Dict[str, List[str]]
    wait_timeout: int
    navigation_timeout: int


class BaseCommunityScaper(ABC):
    """
    ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë˜í¼ ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
    
    í…œí”Œë¦¿ ë©”ì„œë“œ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ê³µí†µ ë¡œì§ì€ ê¸°ë³¸ í´ë˜ìŠ¤ì—ì„œ ì²˜ë¦¬í•˜ê³ ,
    ì‚¬ì´íŠ¸ë³„ ì°¨ì´ì ë§Œ í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•˜ë„ë¡ ì„¤ê³„
    
    ì›Œí¬í”Œë¡œìš°: ê²Œì‹œíŒ ëª©ë¡ â†’ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ â†’ ì„ ë³„ â†’ ìƒì„¸ ìŠ¤í¬ë˜í•‘ â†’ ì €ì¥
    """
    
    def __init__(self, site_config: SiteConfig):
        self.site_config = site_config
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        self.playwright = None
        
        # í•œêµ­ ì‹œê°„ëŒ€ ì„¤ì •
        self.kst = pytz.timezone('Asia/Seoul')
        
        # ê³µí†µ ë¸Œë¼ìš°ì € ì„¤ì •
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
    
    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        await self.setup_browser()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        await self.close_browser()
    
    # ê³µí†µ ë¸Œë¼ìš°ì € ê´€ë¦¬ ë©”ì„œë“œë“¤
    async def setup_browser(self):
        """ë¸Œë¼ìš°ì € ì„¤ì • ë° ì´ˆê¸°í™” (ê³µí†µ ë¡œì§)"""
        try:
            self.playwright = await async_playwright().start()
            
            self.browser = await self.playwright.chromium.launch(
                headless=False,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-blink-features=AutomationControlled',
                    '--window-size=1920,1080'
                ]
            )
            
            self.page = await self.browser.new_page()
            await stealth_async(self.page)
            
            await self.page.set_viewport_size({"width": 1920, "height": 1080})
            await self.page.set_extra_http_headers({
                'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8'
            })
            
            logger.info(f"âœ… {self.get_site_name()} ë¸Œë¼ìš°ì € ì„¤ì • ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë¸Œë¼ìš°ì € ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
    
    async def close_browser(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ (ê³µí†µ ë¡œì§)"""
        try:
            if self.page and not self.page.is_closed():
                await asyncio.wait_for(self.page.close(), timeout=5.0)
                self.page = None
            
            if self.browser and self.browser.is_connected():
                contexts = self.browser.contexts
                for context in contexts:
                    if not context.is_closed():
                        await asyncio.wait_for(context.close(), timeout=3.0)
                
                await asyncio.wait_for(self.browser.close(), timeout=10.0)
                self.browser = None
            
            if self.playwright:
                await asyncio.wait_for(self.playwright.stop(), timeout=5.0)
                self.playwright = None
            
            await asyncio.sleep(0.5)
            import gc
            gc.collect()
            
            logger.info(f"âœ… {self.get_site_name()} ë¸Œë¼ìš°ì € ì¢…ë£Œ ì™„ë£Œ")
            
        except Exception as e:
            logger.debug(f"ë¸Œë¼ìš°ì € ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            self.page = None
            self.browser = None
            self.playwright = None
    
    # í…œí”Œë¦¿ ë©”ì„œë“œë“¤ (ê³µí†µ ì›Œí¬í”Œë¡œìš°)
    async def scrape_board_list(self, board_url: str, page: int = 1) -> List[Dict]:
        """
        ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ (í…œí”Œë¦¿ ë©”ì„œë“œ)
        
        ì›Œí¬í”Œë¡œìš°:
        1. í˜ì´ì§€ ì´ë™
        2. ê²Œì‹œê¸€ ëª©ë¡ ìš”ì†Œ ëŒ€ê¸°
        3. ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ (ì‚¬ì´íŠ¸ë³„ êµ¬í˜„)
        """
        try:
            logger.info(f"ğŸ§ª {self.get_site_name()} ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {board_url}")
            
            if self.page is None:
                raise Exception("ë¸Œë¼ìš°ì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # 1. í˜ì´ì§€ ì´ë™
            await self.navigate_to_board(board_url, page)
            
            # 2. ê²Œì‹œê¸€ ëª©ë¡ ìš”ì†Œ ëŒ€ê¸°
            await self.wait_for_board_elements()
            
            # 3. ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ (ì‚¬ì´íŠ¸ë³„ êµ¬í˜„)
            posts = await self.extract_board_posts()
            
            logger.info(f"âœ… {self.get_site_name()} ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(posts)}ê°œ")
            return posts
            
        except Exception as e:
            logger.error(f"ğŸ’¥ {self.get_site_name()} ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    async def scrape_post_detail(self, post_url: str) -> Dict:
        """
        ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ (í…œí”Œë¦¿ ë©”ì„œë“œ)
        
        ì›Œí¬í”Œë¡œìš°:
        1. í˜ì´ì§€ ì´ë™
        2. ê²Œì‹œê¸€ ìš”ì†Œ ëŒ€ê¸°
        3. ë°ì´í„° ì¶”ì¶œ (ë©”íƒ€ë°ì´í„°, ë³¸ë¬¸, ëŒ“ê¸€)
        4. CommunityPost ëª¨ë¸ êµ¬ì¡°ë¡œ ê²°ê³¼ êµ¬ì„±
        """
        try:
            logger.info(f"ğŸ§ª {self.get_site_name()} ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {post_url}")
            
            if self.page is None:
                raise Exception("ë¸Œë¼ìš°ì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # 1. í˜ì´ì§€ ì´ë™
            await self.navigate_to_post(post_url)
            
            # 2. ê²Œì‹œê¸€ ìš”ì†Œ ëŒ€ê¸°
            await self.wait_for_post_elements()
            
            # 3. ë°ì´í„° ì¶”ì¶œ
            post_id = self.parse_post_id_from_url(post_url)
            metadata = await self.extract_post_metadata()
            content = await self.extract_content_in_order()
            comments = await self.extract_comments_data()
            
            # ì‹¤ì œ ì¶”ì¶œëœ ëŒ“ê¸€ ìˆ˜ë¡œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata['comment_count'] = len(comments)
            
            # 4. CommunityPost ëª¨ë¸ êµ¬ì¡°ë¡œ ê²°ê³¼ êµ¬ì„±
            result = {
                'post_id': post_id,
                'post_url': post_url,
                'scraped_at': datetime.now(self.kst).isoformat(),
                'metadata': metadata,
                'content': content,
                'comments': comments,
                'experiment_purpose': f'{self.get_site_name()}_post_reproduction',
                'page_title': await self.page.title()
            }
            
            logger.info(f"âœ… {self.get_site_name()} ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(content)}ê°œ ì½˜í…ì¸ , {len(comments)}ê°œ ëŒ“ê¸€")
            return result
            
        except Exception as e:
            logger.error(f"ğŸ’¥ {self.get_site_name()} ê²Œì‹œê¸€ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
            raise
    
    async def scrape_board_with_selection(self, board_url: str, criteria_count: int = 3) -> Dict[str, List[Dict]]:
        """
        ê²Œì‹œíŒ ìŠ¤í¬ë˜í•‘ ë° ì§€í‘œë³„ ì„ ë³„ (í†µí•© ì›Œí¬í”Œë¡œìš°)
        
        ì›Œí¬í”Œë¡œìš°:
        1. ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘
        2. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        3. ì§€í‘œë³„ ì„ ë³„ (ì¶”ì²œìˆ˜, ëŒ“ê¸€ìˆ˜, ì¡°íšŒìˆ˜)
        4. ì„ ë³„ëœ ê²Œì‹œê¸€ ë°˜í™˜
        """
        try:
            logger.info(f"ğŸš€ {self.get_site_name()} ì§€í‘œë³„ ì„ ë³„ ìŠ¤í¬ë˜í•‘ ì‹œì‘")
            
            # 1. ê²Œì‹œíŒ ëª©ë¡ ìŠ¤í¬ë˜í•‘
            posts_with_metadata = await self.scrape_board_list(board_url)
            
            if not posts_with_metadata:
                logger.warning("âš ï¸ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
            
            # 2. ì§€í‘œë³„ ì„ ë³„
            selected_posts = self.select_posts_by_criteria(posts_with_metadata, criteria_count)
            
            logger.info(f"âœ… {self.get_site_name()} ì§€í‘œë³„ ì„ ë³„ ì™„ë£Œ")
            return selected_posts
            
        except Exception as e:
            logger.error(f"ğŸ’¥ {self.get_site_name()} ì§€í‘œë³„ ì„ ë³„ ì‹¤íŒ¨: {e}")
            return {}
    
    # ê³µí†µ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    async def navigate_to_board(self, board_url: str, page: int):
        """ê²Œì‹œíŒ í˜ì´ì§€ ì´ë™ (ê³µí†µ ë¡œì§)"""
        if page > 1:
            separator = '&' if '?' in board_url else '?'
            board_url = f"{board_url}{separator}page={page}"
        
        await self.page.goto(board_url, wait_until="networkidle", 
                           timeout=self.site_config.navigation_timeout)
    
    async def navigate_to_post(self, post_url: str):
        """ê²Œì‹œê¸€ í˜ì´ì§€ ì´ë™ (ê³µí†µ ë¡œì§)"""
        await self.page.goto(post_url, wait_until="networkidle", 
                           timeout=self.site_config.navigation_timeout)
    
    def make_absolute_url(self, url: str) -> str:
        """ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜ (ê³µí†µ ë¡œì§)"""
        if url.startswith('//'):
            return 'https:' + url
        elif url.startswith('/'):
            return urljoin(self.site_config.base_url, url)
        return url
    
    def select_posts_by_criteria(self, posts: List[Dict], criteria_count: int = 3) -> Dict[str, List[Dict]]:
        """
        ì§€í‘œë³„ë¡œ ìƒìœ„ ê²Œì‹œê¸€ ì„ ë³„ (ì¤‘ë³µ ì œê±°)
        
        Args:
            posts: ê²Œì‹œê¸€ ëª©ë¡
            criteria_count: ê° ê¸°ì¤€ë³„ ì„ ë³„í•  ê²Œì‹œê¸€ ìˆ˜
        
        Returns:
            Dict: ê¸°ì¤€ë³„ ì„ ë³„ëœ ê²Œì‹œê¸€ ëª©ë¡
        """
        try:
            selected_posts = {
                'likes': [],
                'comments': [],
                'views': []
            }
            
            selected_post_ids = set()  # ì¤‘ë³µ ë°©ì§€ìš©
            
            # 1. ì¶”ì²œìˆ˜ ê¸°ì¤€ ìƒìœ„ ì„ ë³„
            likes_sorted = sorted(posts, key=lambda x: x.get('like_count', 0), reverse=True)
            for post in likes_sorted:
                if len(selected_posts['likes']) >= criteria_count:
                    break
                if post.get('post_id') not in selected_post_ids:
                    selected_posts['likes'].append(post)
                    selected_post_ids.add(post.get('post_id'))
            
            # 2. ëŒ“ê¸€ìˆ˜ ê¸°ì¤€ ìƒìœ„ ì„ ë³„ (ì¤‘ë³µ ì œì™¸)
            comments_sorted = sorted(posts, key=lambda x: x.get('comment_count', 0), reverse=True)
            for post in comments_sorted:
                if len(selected_posts['comments']) >= criteria_count:
                    break
                if post.get('post_id') not in selected_post_ids:
                    selected_posts['comments'].append(post)
                    selected_post_ids.add(post.get('post_id'))
            
            # 3. ì¡°íšŒìˆ˜ ê¸°ì¤€ ìƒìœ„ ì„ ë³„ (ì¤‘ë³µ ì œì™¸)
            views_sorted = sorted(posts, key=lambda x: x.get('view_count', 0), reverse=True)
            for post in views_sorted:
                if len(selected_posts['views']) >= criteria_count:
                    break
                if post.get('post_id') not in selected_post_ids:
                    selected_posts['views'].append(post)
                    selected_post_ids.add(post.get('post_id'))
            
            # ë¡œê¹…
            total_selected = sum(len(posts) for posts in selected_posts.values())
            logger.info(f"âœ… ê²Œì‹œê¸€ ì„ ë³„ ì™„ë£Œ: ì´ {total_selected}ê°œ")
            for criteria, posts_list in selected_posts.items():
                logger.info(f"  - {criteria}: {len(posts_list)}ê°œ")
            
            return selected_posts
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ê²Œì‹œê¸€ ì„ ë³„ ì‹¤íŒ¨: {e}")
            return {'likes': [], 'comments': [], 'views': []}
    
    # ì¶”ìƒ ë©”ì„œë“œë“¤ (ì‚¬ì´íŠ¸ë³„ êµ¬í˜„ í•„ìš”)
    @abstractmethod
    def get_site_name(self) -> str:
        """ì‚¬ì´íŠ¸ ì´ë¦„ ë°˜í™˜"""
        pass
    
    @abstractmethod
    async def wait_for_board_elements(self):
        """ê²Œì‹œíŒ ìš”ì†Œ ë¡œë”© ëŒ€ê¸°"""
        pass
    
    @abstractmethod
    async def wait_for_post_elements(self):
        """ê²Œì‹œê¸€ ìš”ì†Œ ë¡œë”© ëŒ€ê¸°"""
        pass
    
    @abstractmethod
    async def extract_board_posts(self) -> List[Dict]:
        """ê²Œì‹œíŒì—ì„œ ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ (ë©”íƒ€ë°ì´í„° í¬í•¨)"""
        pass
    
    @abstractmethod
    async def extract_post_metadata(self) -> Dict:
        """ê²Œì‹œê¸€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        pass
    
    @abstractmethod
    async def extract_content_in_order(self) -> List[Dict]:
        """ê²Œì‹œê¸€ ë³¸ë¬¸ ë‚´ìš© ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ"""
        pass
    
    @abstractmethod
    async def extract_comments_data(self) -> List[Dict]:
        """ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ"""
        pass
    
    @abstractmethod
    def parse_post_id_from_url(self, url: str) -> str:
        """URLì—ì„œ ê²Œì‹œê¸€ ID ì¶”ì¶œ"""
        pass


class FMKoreaConfig:
    """FMì½”ë¦¬ì•„ ì‚¬ì´íŠ¸ ì„¤ì •"""
    
    def __init__(self):
        self.base_url = "https://www.fmkorea.com"
        self.wait_timeout = 10000
        self.navigation_timeout = 30000
        
        # FMì½”ë¦¬ì•„ íŠ¹í™” ì…€ë ‰í„°ë“¤ (ê¸°ì¡´ ìŠ¤í¬ë˜í¼ì—ì„œ ê²€ì¦ëœ ê²ƒë“¤)
        self.selectors = {
            'title': [
                '.xe_content h1',
                '.board_title',
                'h1.title',
                '.document_title'
            ],
            'author': [
                '.member_info .nickname',
                '.author .nickname',
                '.writer .nickname'
            ],
            'date': [
                '.date',
                '.time',
                '.regdate'
            ],
            'post_container': [
                '.xe_content .document_content',
                '.document_content',
                '.content'
            ],
            'board_list': [
                '.fmk_list_table tbody tr',
                '.board_list tbody tr'
            ]
        }


class RuliwebConfig:
    """ë£¨ë¦¬ì›¹ ì‚¬ì´íŠ¸ ì„¤ì •"""
    
    def __init__(self):
        self.base_url = "https://bbs.ruliweb.com"
        self.wait_timeout = 10000
        self.navigation_timeout = 30000
        
        # ë£¨ë¦¬ì›¹ íŠ¹í™” ì…€ë ‰í„°ë“¤ (ê¸°ì¡´ ìŠ¤í¬ë˜í¼ì—ì„œ ê²€ì¦ëœ ê²ƒë“¤)
        self.selectors = {
            'title': [
                '.board_main_top .subject_text',
                '.subject_text',
                'h1.title'
            ],
            'author': [
                '.board_main_top .nick',
                '.writer .nick',
                '.user .nick'
            ],
            'date': [
                '.board_main_top .time',
                '.time',
                '.regdate'
            ],
            'post_container': [
                '.view_content .article_content',
                '.article_content',
                '.content'
            ],
            'board_list': [
                '.board_list_table tbody tr.table_body',
                '.board_list tbody tr'
            ]
        } 