"""
ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í¼ v2 (ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤ ê¸°ë°˜)

ì£¼ìš” ê°œì„ ì‚¬í•­:
- BaseCommunityScaper ìƒì†ìœ¼ë¡œ ê³µí†µ ë¡œì§ ì¬ì‚¬ìš© (line 20-50)
- ê¸°ì¡´ HTML êµ¬ì¡° ë¶„ì„ ë¡œì§ ì™„ì „ í˜¸í™˜ (line 52-120)
- ëŒ“ê¸€ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§ ìœ ì§€ (line 122-200)
- ê²Œì‹œíŒ ëª©ë¡ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì¶”ê°€ (line 202-280)
- CommunityPost ëª¨ë¸ ì¶œë ¥ í†µí•© (line 282-320)

ì‘ì„±ì: AI Assistant
ì‘ì„±ì¼: 2025-01-28
ëª©ì : í†µì¼ëœ êµ¬ì¡°ë¡œ ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í•‘ (ê¸°ì¡´ ê¸°ëŠ¥ ì™„ì „ í˜¸í™˜)
"""

from typing import List, Dict, Optional
import re
from loguru import logger
from urllib.parse import urljoin

from .base_scraper import BaseCommunityScaper, RuliwebConfig


class RuliwebScraper(BaseCommunityScaper):
    """ë£¨ë¦¬ì›¹ ìŠ¤í¬ë˜í¼ v2 (í†µì¼ëœ êµ¬ì¡° + ê¸°ì¡´ ë¡œì§ ì™„ì „ í˜¸í™˜)"""
    
    def __init__(self):
        super().__init__(RuliwebConfig())
    
    def get_site_name(self) -> str:
        return 'ruliweb'
    
    async def wait_for_board_elements(self):
        """ê²Œì‹œíŒ ìš”ì†Œ ë¡œë”© ëŒ€ê¸° (ë£¨ë¦¬ì›¹ íŠ¹í™”)"""
        try:
            await self.page.wait_for_selector('.board_list_table tbody tr', 
                                            timeout=self.site_config.wait_timeout)
        except:
            logger.warning("âš ï¸ ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    async def wait_for_post_elements(self):
        """ê²Œì‹œê¸€ ìš”ì†Œ ë¡œë”© ëŒ€ê¸° (ë£¨ë¦¬ì›¹ íŠ¹í™”)"""
        try:
            await self.page.wait_for_selector('.board_main_top, .view_content', 
                                            timeout=self.site_config.wait_timeout)
        except:
            logger.warning("âš ï¸ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ë³¸ë¬¸ ì˜ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    async def extract_board_posts(self) -> List[Dict]:
        """
        ê²Œì‹œíŒì—ì„œ ê²Œì‹œê¸€ ëª©ë¡ ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™” + ë©”íƒ€ë°ì´í„° í¬í•¨)
        
        ê¸°ì¡´ extract_board_list ë¡œì§ì„ í™œìš©í•˜ë˜ ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¶”ì¶œ
        """
        try:
            posts = []
            
            # ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ í–‰ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ í™œìš©)
            post_rows = await self.page.query_selector_all('.board_list_table tbody tr.table_body:not(.notice):not(.list_inner)')
            
            if not post_rows:
                logger.warning("âš ï¸ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ í–‰ ë°œê²¬: {len(post_rows)}ê°œ")
            
            # ê° ê²Œì‹œê¸€ í–‰ì—ì„œ ì •ë³´ ì¶”ì¶œ
            for row in post_rows:
                try:
                    post_data = await self.extract_post_info_from_row(row)
                    if post_data and post_data.get('post_url'):
                        posts.append(post_data)
                        logger.debug(f"ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ì¶”ì¶œ: {post_data['title'][:30]}... (ì¶”ì²œ:{post_data.get('like_count', 0)}, ëŒ“ê¸€:{post_data.get('comment_count', 0)}, ì¡°íšŒ:{post_data.get('view_count', 0)})")
                except Exception as e:
                    logger.debug(f"ê²Œì‹œê¸€ í–‰ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ëª©ë¡ ì¶”ì¶œ ì™„ë£Œ: {len(posts)}ê°œ")
            return posts
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ëª©ë¡ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def extract_post_info_from_row(self, row_element) -> Optional[Dict]:
        """
        ê²Œì‹œê¸€ í–‰ì—ì„œ ê¸°ë³¸ ì •ë³´ + ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”)
        
        ê¸°ì¡´ extract_board_post_info ë¡œì§ì„ í™•ì¥í•˜ì—¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        """
        try:
            post_info = {}
            
            # ê²Œì‹œê¸€ ID
            try:
                id_element = await row_element.query_selector('td.id')
                if id_element:
                    post_id_text = await id_element.inner_text()
                    post_info['post_id'] = post_id_text.strip()
            except:
                post_info['post_id'] = 'unknown'
            
            # ì œëª© ë° URL (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                subject_element = await row_element.query_selector('td.subject a.subject_link')
                if not subject_element:
                    return None
                
                title_text = await subject_element.inner_text()
                post_url = await subject_element.get_attribute('href')
                
                if not title_text or not post_url:
                    return None
                
                post_info['title'] = title_text.strip()
                
                # ì ˆëŒ€ URLë¡œ ë³€í™˜
                if not post_url.startswith('http'):
                    post_info['post_url'] = urljoin(self.site_config.base_url, post_url)
                else:
                    post_info['post_url'] = post_url
                
                # URLì—ì„œ ê²Œì‹œê¸€ ID ì¶”ì¶œ (ë” ì •í™•í•œ ID)
                url_post_id = self.parse_post_id_from_url(post_info['post_url'])
                if url_post_id != 'unknown':
                    post_info['post_id'] = url_post_id
                
            except Exception as e:
                logger.debug(f"ì œëª©/URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                return None
            
            # ëŒ“ê¸€ ìˆ˜ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                reply_element = await row_element.query_selector('td.subject .num_reply')
                if reply_element:
                    reply_text = await reply_element.inner_text()
                    reply_match = re.search(r'\((\d+)\)', reply_text)
                    if reply_match:
                        post_info['comment_count'] = int(reply_match.group(1))
                    else:
                        post_info['comment_count'] = 0
                else:
                    post_info['comment_count'] = 0
            except:
                post_info['comment_count'] = 0
            
            # ì‘ì„±ì (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                writer_element = await row_element.query_selector('td.writer a')
                if writer_element:
                    author_text = await writer_element.inner_text()
                    post_info['author'] = author_text.strip()
                else:
                    post_info['author'] = 'ìµëª…'
            except:
                post_info['author'] = 'ìµëª…'
            
            # ê³µì§€ê¸€ í•„í„°ë§ (ê´€ë¦¬ì ê²Œì‹œê¸€ ì œì™¸)
            if self.is_notice_post(post_info['title'], post_info['author']):
                logger.debug(f"ê³µì§€ê¸€ ì œì™¸: {post_info['title'][:30]}... (ì‘ì„±ì: {post_info['author']})")
                return None
            
            # ì¶”ì²œìˆ˜ (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                recommend_element = await row_element.query_selector('td.recomd')
                if recommend_element:
                    recommend_text = await recommend_element.inner_text()
                    if recommend_text.strip().isdigit():
                        post_info['like_count'] = int(recommend_text.strip())
                    else:
                        post_info['like_count'] = 0
                else:
                    post_info['like_count'] = 0
            except:
                post_info['like_count'] = 0
            
            # ì¡°íšŒìˆ˜ (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                hit_element = await row_element.query_selector('td.hit')
                if hit_element:
                    hit_text = await hit_element.inner_text()
                    if hit_text.strip().isdigit():
                        post_info['view_count'] = int(hit_text.strip())
                    else:
                        post_info['view_count'] = 0
                else:
                    post_info['view_count'] = 0
            except:
                post_info['view_count'] = 0
            
            # ì‘ì„±ì‹œê°„ (ê¸°ì¡´ ë¡œì§ í™œìš©)
            try:
                time_element = await row_element.query_selector('td.time')
                if time_element:
                    time_text = await time_element.inner_text()
                    post_info['date'] = time_text.strip()
                else:
                    post_info['date'] = ''
            except:
                post_info['date'] = ''
            
            return post_info
            
        except Exception as e:
            logger.debug(f"ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def extract_post_metadata(self) -> Dict:
        """
        ê²Œì‹œê¸€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”)
        
        ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ê°œì„ ëœ ì…€ë ‰í„° ì‚¬ìš©
        """
        try:
            metadata = {}
            
            # ì œëª© ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: .subject_text .subject_inner_text)
            title_selectors = [
                '.subject_text .subject_inner_text',  # ì‹¤ì œ êµ¬ì¡°
                '.subject_inner_text',
                '.subject_text',
                'h4.subject .subject_text',
                'h4.subject'
            ]
            
            for selector in title_selectors:
                try:
                    title_element = await self.page.query_selector(selector)
                    if title_element:
                        title_text = await title_element.inner_text()
                        if title_text and title_text.strip():
                            metadata['title'] = title_text.strip()
                            logger.info(f"âœ… ì œëª© ì¶”ì¶œ ì„±ê³µ: {title_text.strip()}")
                            break
                except:
                    continue
            
            # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: .subject_text .category_text)
            try:
                category_element = await self.page.query_selector('.subject_text .category_text')
                if category_element:
                    category_text = await category_element.inner_text()
                    if category_text and category_text.strip():
                        # [ì¡ë‹´] í˜•íƒœì—ì„œ ëŒ€ê´„í˜¸ ì œê±°
                        category = category_text.strip().replace('[', '').replace(']', '')
                        metadata['category'] = category
                        logger.info(f"âœ… ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì„±ê³µ: {category}")
            except:
                pass
            
            # ì‘ì„±ì ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: .user_info .nick)
            author_selectors = [
                '.user_info .nick',  # ì‹¤ì œ êµ¬ì¡°
                '.nick',
                '.user_view .nick',
                '.user_info_wrapper .nick'
            ]
            
            for selector in author_selectors:
                try:
                    author_element = await self.page.query_selector(selector)
                    if author_element:
                        author_text = await author_element.inner_text()
                        if author_text and author_text.strip():
                            metadata['author'] = author_text.strip()
                            logger.info(f"âœ… ì‘ì„±ì ì¶”ì¶œ ì„±ê³µ: {author_text.strip()}")
                            break
                except:
                    continue
            
            # ì‘ì„± ì‹œê°„ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: .regdate)
            date_selectors = [
                '.regdate',  # ì‹¤ì œ êµ¬ì¡°
                '.user_info .regdate',
                'span.regdate',
                '.user_view .regdate'
            ]
            
            for selector in date_selectors:
                try:
                    date_element = await self.page.query_selector(selector)
                    if date_element:
                        date_text = await date_element.inner_text()
                        if date_text and date_text.strip():
                            metadata['date'] = date_text.strip()
                            logger.info(f"âœ… ì‘ì„±ì‹œê°„ ì¶”ì¶œ ì„±ê³µ: {date_text.strip()}")
                            break
                except:
                    continue
            
            # í†µê³„ ì •ë³´ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: .user_info p, .mini_profile .info)
            view_count = 0
            like_count = 0
            dislike_count = 0
            comment_count = 0
            
            try:
                # ë¯¸ë‹ˆ í”„ë¡œí•„ì—ì„œ í†µê³„ ì •ë³´ ì¶”ì¶œ
                mini_profile = await self.page.query_selector('.mini_profile .info')
                if mini_profile:
                    stats_text = await mini_profile.inner_text()
                    logger.debug(f"ë¯¸ë‹ˆ í”„ë¡œí•„ í†µê³„ í…ìŠ¤íŠ¸: {stats_text}")
                    
                    # ì¶”ì²œìˆ˜ ì¶”ì¶œ
                    like_match = re.search(r'(\d+)', stats_text)
                    if like_match:
                        like_count = int(like_match.group(1))
                    
                    # ëŒ“ê¸€ìˆ˜ ì¶”ì¶œ
                    comment_match = re.search(r'(\d+)', stats_text.split('|')[1] if '|' in stats_text else '')
                    if comment_match:
                        comment_count = int(comment_match.group(1))
                    
                    # ì¡°íšŒìˆ˜ ì¶”ì¶œ
                    view_match = re.search(r'(\d+)', stats_text.split('|')[2] if stats_text.count('|') >= 2 else '')
                    if view_match:
                        view_count = int(view_match.group(1))
                
                # ì‚¬ìš©ì ì •ë³´ ì˜ì—­ì—ì„œë„ ì¶”ê°€ í™•ì¸
                user_info_stats = await self.page.query_selector_all('.user_info p')
                for stat_element in user_info_stats:
                    stat_text = await stat_element.inner_text()
                    
                    # ì¶”ì²œìˆ˜
                    if 'ì¶”ì²œ' in stat_text:
                        like_match = re.search(r'ì¶”ì²œ\s*(\d+)', stat_text)
                        if like_match:
                            like_count = int(like_match.group(1))
                    
                    # ì¡°íšŒìˆ˜
                    if 'ì¡°íšŒ' in stat_text:
                        view_match = re.search(r'ì¡°íšŒ\s*(\d+)', stat_text)
                        if view_match:
                            view_count = int(view_match.group(1))
                    
                    # ë¹„ì¶”ë ¥
                    if 'ë¹„ì¶”ë ¥' in stat_text:
                        dislike_match = re.search(r'ë¹„ì¶”ë ¥\s*(\d+)', stat_text)
                        if dislike_match:
                            dislike_count = int(dislike_match.group(1))
                
                logger.info(f"âœ… í†µê³„ ì¶”ì¶œ ì„±ê³µ - ì¡°íšŒ:{view_count}, ì¶”ì²œ:{like_count}, ë¹„ì¶”ë ¥:{dislike_count}, ëŒ“ê¸€:{comment_count}")
                
            except Exception as e:
                logger.debug(f"í†µê³„ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ëŒ“ê¸€ìˆ˜ ë³„ë„ í™•ì¸ (reply_count inputì—ì„œ)
            try:
                reply_count_input = await self.page.query_selector('#reply_count')
                if reply_count_input:
                    reply_count_value = await reply_count_input.get_attribute('value')
                    if reply_count_value and reply_count_value.isdigit():
                        comment_count = int(reply_count_value)
                        logger.info(f"âœ… ëŒ“ê¸€ìˆ˜ ë³„ë„ ì¶”ì¶œ: {comment_count}")
            except:
                pass
            
            metadata['view_count'] = view_count
            metadata['like_count'] = like_count
            metadata['dislike_count'] = dislike_count
            metadata['comment_count'] = comment_count
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {metadata}")
            return metadata
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    async def extract_content_in_order(self) -> List[Dict]:
        """
        ê²Œì‹œê¸€ ë³¸ë¬¸ ë‚´ìš© ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”)
        
        ì‹¤ì œ HTML êµ¬ì¡°: .view_content article
        """
        try:
            content_list: List[Dict] = []
            order = 0
            
            # ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ì°¾ê¸° (ì‹¤ì œ HTML êµ¬ì¡°)
            article_selectors = [
                '.view_content article',  # ì‹¤ì œ êµ¬ì¡°
                '.view_content',
                'article',
                '.board_main_view .view_content',
                '.autolink article'
            ]
            
            article_element = None
            for selector in article_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        article_element = element
                        logger.info(f"âœ… ë£¨ë¦¬ì›¹ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ë°œê²¬: {selector}")
                        break
                except:
                    continue
            
            if not article_element:
                logger.warning("âš ï¸ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ë³¸ë¬¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            try:
                content_preview = await article_element.inner_text()
                logger.info(f"ğŸ“„ ë³¸ë¬¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content_preview[:100]}...")
            except:
                pass
            
            # ê¸°ì¡´ extract_elements_improved ë¡œì§ ì‚¬ìš©
            order = await self.extract_elements_improved(article_element, content_list, order)
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ì½˜í…ì¸  ì¶”ì¶œ ì™„ë£Œ: {len(content_list)}ê°œ ìš”ì†Œ")
            return content_list
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def extract_elements_improved(self, parent_element, content_list: List[Dict], order_start: int) -> int:
        """
        ê°œì„ ëœ ìš”ì†Œ ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ì™„ì „ í™œìš©)
        
        ê¸°ì¡´ ruliweb_scraper.pyì˜ extract_elements_improved ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        """
        try:
            order = order_start
            
            # ëª¨ë“  ìì‹ ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
            child_elements = await parent_element.query_selector_all('*')
            
            processed_images = set()  # ì¤‘ë³µ ì´ë¯¸ì§€ ë°©ì§€
            
            for element in child_elements:
                try:
                    tag_name = await element.evaluate('el => el.tagName.toLowerCase()')
                    
                    # ì´ë¯¸ì§€ ì²˜ë¦¬
                    if tag_name == 'img':
                        img_src = await element.get_attribute('src')
                        if img_src and img_src not in processed_images:
                            processed_images.add(img_src)
                            
                            # ì´ë¯¸ì§€ ë§í¬ ì°¾ê¸°
                            parent_link = await element.evaluate('''
                                el => {
                                    let parent = el.parentElement;
                                    while (parent && parent.tagName.toLowerCase() !== 'a') {
                                        parent = parent.parentElement;
                                    }
                                    return parent ? parent.href : null;
                                }
                            ''')
                            
                            image_data = await self.extract_image_data(element, parent_link, order)
                            if image_data:
                                content_list.append(image_data)
                                order += 1
                    
                    # ë¹„ë””ì˜¤ ì²˜ë¦¬
                    elif tag_name in ['video', 'iframe']:
                        video_data = await self.extract_video_data(element, order)
                        if video_data:
                            content_list.append(video_data)
                            order += 1
                    
                    # í…ìŠ¤íŠ¸ ì²˜ë¦¬ (p, div ë“±)
                    elif tag_name in ['p', 'div', 'span', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                        # ìì‹ ìš”ì†Œê°€ ì—†ëŠ” í…ìŠ¤íŠ¸ë§Œ ì²˜ë¦¬
                        has_child_elements = await element.evaluate('el => el.children.length > 0')
                        if not has_child_elements:
                            text_data = await self.extract_text_data(element, order)
                            if text_data and text_data.get('data', {}).get('text', '').strip():
                                content_list.append(text_data)
                                order += 1
                
                except Exception as e:
                    logger.debug(f"ìš”ì†Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                    continue
            
            return order
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ìš”ì†Œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return order_start
    
    async def extract_image_data(self, img_element, parent_link: Optional[str], order: int) -> Optional[Dict]:
        """
        ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”, FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ êµ¬ì¡°)
        
        ê¸°ì¡´ extract_image_data ë¡œì§ ì™„ì „ í™œìš©
        """
        try:
            src = await img_element.get_attribute('src')
            if not src:
                return None
            
            # ì ˆëŒ€ URLë¡œ ë³€í™˜
            src = self.make_absolute_url(src)
            
            # ì´ë¯¸ì§€ ì†ì„± ì¶”ì¶œ
            alt = await img_element.get_attribute('alt') or ''
            width = await img_element.get_attribute('width') or ''
            height = await img_element.get_attribute('height') or ''
            style = await img_element.get_attribute('style') or ''
            class_name = await img_element.get_attribute('class') or ''
            title = await img_element.get_attribute('title') or ''
            
            # FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ ì¤‘ì²© êµ¬ì¡°
            return {
                'type': 'image',
                'order': order,
                'data': {
                    'src': src,
                    'alt': alt,
                    'width': width,
                    'height': height,
                    'href': parent_link or '',
                    'data_original': src,  # ë£¨ë¦¬ì›¹ì€ ì›ë³¸ ì´ë¯¸ì§€ ì§ì ‘ ì œê³µ
                    'original_src': src,
                    'style': style,
                    'class': class_name,
                    'title': title,
                    'link_class': '',
                    'link_rel': ''
                }
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë£¨ë¦¬ì›¹ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def extract_video_data(self, video_element, order: int) -> Optional[Dict]:
        """
        ë¹„ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”, FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ êµ¬ì¡°)
        
        ê¸°ì¡´ extract_video_data ë¡œì§ ì™„ì „ í™œìš©
        """
        try:
            tag_name = await video_element.evaluate('el => el.tagName.toLowerCase()')
            
            if tag_name == 'video':
                src = await video_element.get_attribute('src')
                poster = await video_element.get_attribute('poster') or ''
                width = await video_element.get_attribute('width') or ''
                height = await video_element.get_attribute('height') or ''
                
                # ìë™ì¬ìƒ ì†ì„± ê°ì§€
                autoplay = await video_element.get_attribute('autoplay') is not None
                loop = await video_element.get_attribute('loop') is not None
                muted = await video_element.get_attribute('muted') is not None
                controls = await video_element.get_attribute('controls') is not None
                preload = await video_element.get_attribute('preload') or 'metadata'
                class_name = await video_element.get_attribute('class') or ''
                
                # ìë™ì¬ìƒì´ë©´ ìŒì†Œê±° ì²˜ë¦¬ (ë¸Œë¼ìš°ì € ì •ì±…)
                if autoplay and not muted:
                    muted = True
                
                # FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ ì¤‘ì²© êµ¬ì¡°
                return {
                    'type': 'video',
                    'order': order,
                    'data': {
                        'src': src,
                        'poster': poster,
                        'autoplay': autoplay,
                        'loop': loop,
                        'muted': muted,
                        'controls': controls,
                        'preload': preload,
                        'width': width,
                        'height': height,
                        'class': class_name
                    }
                }
            
            elif tag_name == 'iframe':
                src = await video_element.get_attribute('src')
                width = await video_element.get_attribute('width') or ''
                height = await video_element.get_attribute('height') or ''
                class_name = await video_element.get_attribute('class') or ''
                
                # FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ ì¤‘ì²© êµ¬ì¡°
                return {
                    'type': 'iframe',
                    'order': order,
                    'data': {
                        'src': src,
                        'width': width,
                        'height': height,
                        'class': class_name
                    }
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë£¨ë¦¬ì›¹ ë¹„ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def extract_text_data(self, text_element, order: int) -> Optional[Dict]:
        """
        í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”, FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ êµ¬ì¡°)
        
        ê¸°ì¡´ extract_text_data ë¡œì§ ì™„ì „ í™œìš©
        """
        try:
            text = await text_element.inner_text()
            if not text or not text.strip():
                return None
            
            tag_name = await text_element.evaluate('el => el.tagName.toLowerCase()')
            
            # ìŠ¤íƒ€ì¼ ì •ë³´ ì¶”ì¶œ
            style = await text_element.get_attribute('style') or ''
            class_name = await text_element.get_attribute('class') or ''
            id_attr = await text_element.get_attribute('id') or ''
            innerHTML = await text_element.inner_html()
            
            # FMì½”ë¦¬ì•„ì™€ ë™ì¼í•œ ì¤‘ì²© êµ¬ì¡°
            return {
                'type': 'text',
                'order': order,
                'data': {
                    'tag': tag_name,
                    'text': text.strip(),
                    'id': id_attr,
                    'class': class_name,
                    'style': style,
                    'innerHTML': innerHTML
                }
            }
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë£¨ë¦¬ì›¹ í…ìŠ¤íŠ¸ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    async def extract_comments_data(self) -> List[Dict]:
        """
        ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”, ì‹¤ì œ HTML êµ¬ì¡° ê¸°ë°˜)
        
        ì‹¤ì œ HTML êµ¬ì¡°: .comment_table .comment_element
        """
        try:
            comments = []
            
            # ëŒ“ê¸€ ì»¨í…Œì´ë„ˆ í™•ì¸ (ì‹¤ì œ HTML êµ¬ì¡°)
            comment_container_selectors = [
                '.comment_table',  # ì‹¤ì œ êµ¬ì¡°
                '.comment_view',
                '.comment_view_wrapper',
                '.comment_wrapper'
            ]
            
            comment_wrapper = None
            for selector in comment_container_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        comment_wrapper = element
                        logger.info(f"âœ… ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ì»¨í…Œì´ë„ˆ ë°œê²¬: {selector}")
                        break
                except:
                    continue
            
            if not comment_wrapper:
                logger.info("ğŸ“ ë£¨ë¦¬ì›¹ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ëŒ“ê¸€ ìš”ì†Œë“¤ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡°: tr.comment_element)
            comment_elements = await comment_wrapper.query_selector_all('tr.comment_element')
            
            if not comment_elements:
                logger.warning("âš ï¸ ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ìš”ì†Œ ë°œê²¬: {len(comment_elements)}ê°œ")
            
            # ê° ëŒ“ê¸€ ì¶”ì¶œ
            for index, comment_element in enumerate(comment_elements):
                try:
                    comment_data = await self.extract_single_comment_improved(comment_element, index)
                    if comment_data:
                        comments.append(comment_data)
                        logger.debug(f"ëŒ“ê¸€ ì¶”ì¶œ: {comment_data['author']} - {comment_data['content'][:50]}...")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ì¶”ì¶œ ì‹¤íŒ¨ (ì¸ë±ìŠ¤ {index}): {e}")
                    continue
            
            logger.info(f"âœ… ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ì¶”ì¶œ ì™„ë£Œ: {len(comments)}ê°œ")
            return comments
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ëŒ“ê¸€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def extract_single_comment_improved(self, comment_element, index: int) -> Optional[Dict]:
        """
        ê°œë³„ ëŒ“ê¸€ ì¶”ì¶œ (ì‹¤ì œ HTML êµ¬ì¡° ê¸°ë°˜)
        
        ì‹¤ì œ HTML êµ¬ì¡°:
        - ëŒ“ê¸€ ID: tr#ct_157697516
        - ì‘ì„±ì: .nick .nick_link
        - ë‚´ìš©: .text_wrapper .text
        - ì‹œê°„: .control_box .time
        - ì¶”ì²œìˆ˜: .btn_like .num
        - ë² ìŠ¤íŠ¸: .icon_best
        """
        try:
            # ëŒ“ê¸€ ID ì¶”ì¶œ (ì‹¤ì œ êµ¬ì¡°: tr#ct_157697516)
            comment_id = await comment_element.get_attribute('id') or f'comment_{index}'
            
            # ëŒ€ëŒ“ê¸€ ì—¬ë¶€ í™•ì¸ (ì‹¤ì œ êµ¬ì¡°: .child í´ë˜ìŠ¤)
            is_reply = False
            try:
                class_attr = await comment_element.get_attribute('class') or ''
                if 'child' in class_attr or 'reply' in class_attr:
                    is_reply = True
            except:
                pass
            
            # ë² ìŠ¤íŠ¸ ëŒ“ê¸€ ì—¬ë¶€ í™•ì¸ (ì‹¤ì œ êµ¬ì¡°: .icon_best)
            is_best = False
            try:
                best_element = await comment_element.query_selector('.icon_best')
                if best_element:
                    is_best = True
            except:
                pass
            
            # ì‘ì„±ì ì •ë³´ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„)
            author = 'ìµëª…'
            try:
                author_selectors = [
                    '.nick .nick_link',  # ì‹¤ì œ êµ¬ì¡°
                    '.nick_link',
                    '.nick a',
                    '.nick',
                    '.user_nick',
                    '.writer',
                    'td.writer a',
                    'td.writer'
                ]
                
                for selector in author_selectors:
                    author_element = await comment_element.query_selector(selector)
                    if author_element:
                        author_text = await author_element.inner_text()
                        if author_text and author_text.strip():
                            author = author_text.strip()
                            logger.debug(f"ì‘ì„±ì ì¶”ì¶œ ì„±ê³µ ({selector}): {author}")
                            break
            except Exception as e:
                logger.debug(f"ì‘ì„±ì ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ëŒ“ê¸€ ë‚´ìš© ì¶”ì¶œ (ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„)
            content = ''
            try:
                content_selectors = [
                    '.text_wrapper .text',  # ì‹¤ì œ êµ¬ì¡°
                    '.text',
                    '.comment_text',
                    '.content',
                    'td.text',
                    '.comment_content',
                    '.memo'
                ]
                
                for selector in content_selectors:
                    content_element = await comment_element.query_selector(selector)
                    if content_element:
                        content_text = await content_element.inner_text()
                        if content_text and content_text.strip():
                            content = content_text.strip()
                            logger.debug(f"ëŒ“ê¸€ ë‚´ìš© ì¶”ì¶œ ì„±ê³µ ({selector}): {content[:50]}...")
                            break
                
                # ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì „ì²´ trì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                if not content:
                    all_text = await comment_element.inner_text()
                    if all_text and all_text.strip():
                        # ì‘ì„±ìëª…ê³¼ ì‹œê°„ ë“±ì„ ì œì™¸í•œ ì‹¤ì œ ëŒ“ê¸€ ë‚´ìš©ë§Œ ì¶”ì¶œ
                        lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                        # ì²« ë²ˆì§¸ ì¤„ì´ ì‘ì„±ì, ë§ˆì§€ë§‰ ì¤„ì´ ì‹œê°„ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
                        if len(lines) > 2:
                            content = '\n'.join(lines[1:-1])  # ì¤‘ê°„ ë¶€ë¶„ì´ ì‹¤ì œ ë‚´ìš©
                        elif len(lines) == 2:
                            content = lines[1]  # ë‘ ë²ˆì§¸ ì¤„ì´ ë‚´ìš©
                        logger.debug(f"ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë‚´ìš© ì¶”ì¶œ: {content[:50]}...")
                        
            except Exception as e:
                logger.debug(f"ëŒ“ê¸€ ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ì‘ì„± ì‹œê°„ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„)
            date = ''
            try:
                date_selectors = [
                    '.control_box .time',  # ì‹¤ì œ êµ¬ì¡°
                    '.time',
                    '.regdate',
                    '.date',
                    'td.time',
                    '.comment_time'
                ]
                
                for selector in date_selectors:
                    date_element = await comment_element.query_selector(selector)
                    if date_element:
                        date_text = await date_element.inner_text()
                        if date_text and date_text.strip():
                            date = date_text.strip()
                            logger.debug(f"ì‘ì„±ì‹œê°„ ì¶”ì¶œ ì„±ê³µ ({selector}): {date}")
                            break
                
                # ì‹œê°„ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì‹œê°„ íŒ¨í„´ ì°¾ê¸°
                if not date:
                    all_text = await comment_element.inner_text()
                    import re
                    # ì‹œê°„ íŒ¨í„´ ì°¾ê¸° (ì˜ˆ: 25.06.03 04:13, 04:13, 2025.06.03 ë“±)
                    time_patterns = [
                        r'\d{2}\.\d{2}\.\d{2}\s+\d{2}:\d{2}',  # 25.06.03 04:13
                        r'\d{4}\.\d{2}\.\d{2}\s+\d{2}:\d{2}',  # 2025.06.03 04:13
                        r'\d{2}:\d{2}',  # 04:13
                        r'\d+ë¶„\s*ì „',  # 25ë¶„ ì „
                        r'\d+ì‹œê°„\s*ì „',  # 2ì‹œê°„ ì „
                    ]
                    
                    for pattern in time_patterns:
                        match = re.search(pattern, all_text)
                        if match:
                            date = match.group(0)
                            logger.debug(f"íŒ¨í„´ìœ¼ë¡œ ì‹œê°„ ì¶”ì¶œ: {date}")
                            break
                            
            except Exception as e:
                logger.debug(f"ì‘ì„±ì‹œê°„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ì¶”ì²œ/ë¹„ì¶”ì²œ ìˆ˜ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì…€ë ‰í„° ì‹œë„)
            like_count = 0
            dislike_count = 0
            
            try:
                # ì¶”ì²œìˆ˜ (ë‹¤ì–‘í•œ ì…€ë ‰í„°)
                like_selectors = [
                    '.btn_like .num',  # ì‹¤ì œ êµ¬ì¡°
                    '.like_count',
                    '.recommend',
                    '.btn_recommend .num',
                    'td.recommend'
                ]
                
                for selector in like_selectors:
                    like_element = await comment_element.query_selector(selector)
                    if like_element:
                        like_text = await like_element.inner_text()
                        if like_text and like_text.strip().isdigit():
                            like_count = int(like_text.strip())
                            logger.debug(f"ì¶”ì²œìˆ˜ ì¶”ì¶œ ì„±ê³µ ({selector}): {like_count}")
                            break
                
                # ë¹„ì¶”ì²œìˆ˜ (ë‹¤ì–‘í•œ ì…€ë ‰í„°)
                dislike_selectors = [
                    '.btn_dislike .num',  # ì‹¤ì œ êµ¬ì¡°
                    '.dislike_count',
                    '.btn_unrecommend .num'
                ]
                
                for selector in dislike_selectors:
                    dislike_element = await comment_element.query_selector(selector)
                    if dislike_element:
                        dislike_text = await dislike_element.inner_text()
                        if dislike_text and dislike_text.strip().isdigit():
                            dislike_count = int(dislike_text.strip())
                            logger.debug(f"ë¹„ì¶”ì²œìˆ˜ ì¶”ì¶œ ì„±ê³µ ({selector}): {dislike_count}")
                            break
                            
            except Exception as e:
                logger.debug(f"ì¶”ì²œ/ë¹„ì¶”ì²œìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            
            # ë‚´ìš©ì´ ì—†ëŠ” ëŒ“ê¸€ì€ ì œì™¸í•˜ì§€ ì•Šê³  ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
            if not content:
                logger.warning(f"âš ï¸ ëŒ“ê¸€ ë‚´ìš©ì´ ì—†ìŒ - ID: {comment_id}, ì‘ì„±ì: {author}")
                # ì „ì²´ HTML êµ¬ì¡° í™•ì¸
                try:
                    comment_html = await comment_element.inner_html()
                    logger.debug(f"ëŒ“ê¸€ HTML êµ¬ì¡°: {comment_html[:200]}...")
                except:
                    pass
                return None
            
            comment_data = {
                'id': comment_id,
                'author': author,
                'content': content,
                'date': date,
                'like_count': like_count,
                'dislike_count': dislike_count,
                'is_reply': is_reply,
                'is_best': is_best
            }
            
            logger.debug(f"âœ… ëŒ“ê¸€ ì¶”ì¶œ ì„±ê³µ: {comment_data}")
            return comment_data
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë£¨ë¦¬ì›¹ ê°œë³„ ëŒ“ê¸€ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def parse_post_id_from_url(self, url: str) -> str:
        """
        URLì—ì„œ ê²Œì‹œê¸€ ID ì¶”ì¶œ (ë£¨ë¦¬ì›¹ íŠ¹í™”)
        
        ê¸°ì¡´ parse_post_id_from_url ë¡œì§ ì™„ì „ í™œìš©
        """
        try:
            # ë£¨ë¦¬ì›¹ URL íŒ¨í„´: /read/ìˆ«ì
            match = re.search(r'/read/(\d+)', url)
            if match:
                return match.group(1)
            
            # ë‹¤ë¥¸ íŒ¨í„´ë“¤ë„ ì‹œë„
            match = re.search(r'document_srl=(\d+)', url)
            if match:
                return match.group(1)
            
            return 'unknown'
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 'unknown'


# í¸ì˜ í•¨ìˆ˜ë“¤
async def scrape_ruliweb_board_v2(board_url: str, criteria_count: int = 3) -> Dict[str, List[Dict]]:
    """ë£¨ë¦¬ì›¹ ê²Œì‹œíŒ ì§€í‘œë³„ ì„ ë³„ ìŠ¤í¬ë˜í•‘ í¸ì˜ í•¨ìˆ˜"""
    async with RuliwebScraper() as scraper:
        return await scraper.scrape_board_with_selection(board_url, criteria_count)


async def scrape_ruliweb_post_v2(post_url: str) -> Dict:
    """ë£¨ë¦¬ì›¹ ê²Œì‹œê¸€ ìƒì„¸ ìŠ¤í¬ë˜í•‘ í¸ì˜ í•¨ìˆ˜"""
    async with RuliwebScraper() as scraper:
        return await scraper.scrape_post_detail(post_url) 